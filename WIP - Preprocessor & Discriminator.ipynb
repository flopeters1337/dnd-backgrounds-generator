{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Preprocessor import *\n",
    "from CNNDiscriminator import *\n",
    "\n",
    "%aimport Preprocessor\n",
    "%aimport CNNDiscriminator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, values, labels):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.values = values\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.values[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 40,  0, 28, 45],\n",
       "        [29, 26, 31, 33,  3],\n",
       "        [48, 28, 15, 29, 35],\n",
       "        [18, 16, 24, 42, 27],\n",
       "        [27, 48, 17,  3, 25],\n",
       "        [21, 11, 30, 35,  1],\n",
       "        [46, 39, 25, 30, 44],\n",
       "        [15, 36, 45, 10, 31]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.5220e-01, 3.4780e-01],\n",
       "        [2.9920e-01, 7.0080e-01],\n",
       "        [3.8517e-01, 6.1483e-01],\n",
       "        [1.0118e-02, 9.8988e-01],\n",
       "        [9.9995e-01, 4.8044e-05],\n",
       "        [1.0974e-03, 9.9890e-01],\n",
       "        [4.7708e-06, 1.0000e+00],\n",
       "        [9.9590e-01, 4.1050e-03]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discriminator = CNNDiscriminator.CNNDiscriminator()\n",
    "test = torch.randint(low=0,high=50,size=(8,5)) # 8 sentences of 5 words\n",
    "display(test)\n",
    "a = discriminator(test)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training part : features needed\n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCELoss() # nn.BCEWithLogitsLoss stabler ? \n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "# beta1 = 0.5\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create a batch of data\n",
    "samples = torch.randint(low=0,high=50,size=(400,5))\n",
    "labels = torch.randint(low=0,high=2,size=(samples.size(0),1)).float() \n",
    "train_dataset = MyDataset(samples, labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/50], Loss: 2.5218, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [2/50], Loss: 1.9235, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [3/50], Loss: 5.8824, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [4/50], Loss: 4.2460, Accuracy: 12.50%\n",
      "Epoch [1/1], Step [5/50], Loss: 0.9108, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [6/50], Loss: 5.5763, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [7/50], Loss: 6.4622, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [8/50], Loss: 1.3533, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [9/50], Loss: 3.9195, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [10/50], Loss: 4.0677, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [11/50], Loss: 1.9772, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [12/50], Loss: 4.2313, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [13/50], Loss: 3.8190, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [14/50], Loss: 3.8073, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [15/50], Loss: 3.3673, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [16/50], Loss: 2.9522, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [17/50], Loss: 3.4903, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [18/50], Loss: 3.7989, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [19/50], Loss: 4.2901, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [20/50], Loss: 1.9972, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [21/50], Loss: 5.3697, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [22/50], Loss: 5.4509, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [23/50], Loss: 2.2727, Accuracy: 12.50%\n",
      "Epoch [1/1], Step [24/50], Loss: 1.9387, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [25/50], Loss: 2.0377, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [26/50], Loss: 2.7383, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [27/50], Loss: 3.2078, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [28/50], Loss: 4.1071, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [29/50], Loss: 2.5112, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [30/50], Loss: 4.0306, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [31/50], Loss: 1.4845, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [32/50], Loss: 2.2571, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [33/50], Loss: 3.8146, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [34/50], Loss: 1.6811, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [35/50], Loss: 0.6047, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [36/50], Loss: 2.4861, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [37/50], Loss: 3.7915, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [38/50], Loss: 3.3797, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [39/50], Loss: 2.3034, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [40/50], Loss: 4.2535, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [41/50], Loss: 3.3787, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [42/50], Loss: 7.2247, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [43/50], Loss: 2.8553, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [44/50], Loss: 1.3789, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [45/50], Loss: 1.1509, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [46/50], Loss: 2.7845, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [47/50], Loss: 8.6285, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [48/50], Loss: 5.0718, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [49/50], Loss: 5.9805, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [50/50], Loss: 1.6772, Accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (sentences, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Run the forward pass\n",
    "        outputs = discriminator(sentences)\n",
    "        true_probability = outputs[:,1].unsqueeze(1)\n",
    "        loss = criterion(true_probability, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        predicted = predicted.unsqueeze(1)\n",
    "        correct = (predicted == labels).sum().item() \n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        # Print the results \n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor.Preprocessor()\n",
    "preprocessor.load_dataset('data.xls') # Load the dataset\n",
    "output_sentences, output_descriptions = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2206, 998])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([35555, 25])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output_descriptions.shape, output_sentences.shape)\n",
    "# display(d[0], s[0])\n",
    "\n",
    "vocabulary = preprocessor.vocabulary\n",
    "display(len(vocabulary))\n",
    "\n",
    "desc_original = preprocessor.descriptions_original\n",
    "# display(desc_original[9])\n",
    "\n",
    "desc_tokened = preprocessor.descriptions_tokened\n",
    "sent_tokened = preprocessor.sentences_tokened\n",
    "# display(desc_tokened[9])\n",
    "\n",
    "desc_numeric = preprocessor.descriptions_indexed\n",
    "sent_numeric = preprocessor.sentences_indexed\n",
    "# display(desc_numeric[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test divers size distribution avec desc_numeric or sent_numeric\n",
    "display(len(desc_numeric))\n",
    "\n",
    "lens = [len(d) for d in desc_numeric]\n",
    "plt.hist(lens, bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "# u,c = np.unique(lens, return_counts=True)\n",
    "# display(u,c)\n",
    "\n",
    "lens_filtered = [l for l in lens if 15 <= l <= 900]\n",
    "display(len(lens_filtered))\n",
    "plt.hist(lens_filtered, bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training test for the text\n",
    "samples = output_sentences\n",
    "labels = torch.randint(low=0,high=2,size=(samples.size(0),1)).float() \n",
    "train_dataset = MyDataset(samples, labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "discri_test2 = CNNDiscriminator(voc_size=len(vocabulary)+1)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (sentences, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Run the forward pass\n",
    "        outputs = discri_test2(sentences)\n",
    "        true_probability = outputs[:,1].unsqueeze(1)\n",
    "        loss = criterion(true_probability, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        predicted = predicted.unsqueeze(1)\n",
    "        correct = (predicted == labels).sum().item() \n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        # Print the results \n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
