{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO AFTER : make it more automated (parameters)\n",
    "\n",
    "# Definition of the CNN based discrimantor, inheriting from nn.Module super class\n",
    "class CNNDiscriminator(nn.Module):\n",
    "    \n",
    "    # Constructor of the Discrimator\n",
    "    def __init__(self, batch_size=8, max_seq=5, voc_size=50, embedding_dim=10, \n",
    "                 window_sizes=[1,2,3], n_filters = [300,300,300], n_features_maps=900, n_inter_nodes=200):\n",
    "                \n",
    "        # Call the superclass' constructor\n",
    "        super(CNNDiscriminator, self).__init__()\n",
    "        \n",
    "        # Embedding\n",
    "        self.embedding = nn.Embedding(voc_size, embedding_dim) # Why padding in the TextGan version ? \n",
    "        \n",
    "#         self.conv = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=(2,10), stride=1, padding=0)\n",
    "        \n",
    "        self.tan_layer = nn.Tanh()\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=f, kernel_size=(h,10), stride=1, padding=0) \n",
    "            for h,f in zip(window_sizes, n_filters)\n",
    "        ])\n",
    "        \n",
    "        self.n_features_maps = sum(n_filters)\n",
    "     \n",
    "        # Definition of the classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=self.n_features_maps, out_features=n_inter_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=n_inter_nodes, out_features=2),\n",
    "            nn.Softmax(dim=1)) # Quid formule Text Gan ??? \n",
    "        \n",
    "        # Call the parameters initialization function\n",
    "#         self.init_params() \n",
    "    \n",
    "    def perform_convolution(self, x):\n",
    "        \n",
    "        outputs = [conv(x).squeeze(3) for conv in self.conv_layers] # Apply convolutional with filters size and number of filters\n",
    "        outputs = [self.tan_layer(output) for output in outputs] # Apply tanh function\n",
    "        poolings = [nn.MaxPool1d(output.size(2))for output in outputs] # Prepare the max-pooling filters over time\n",
    "        outputs = [pool(output).squeeze(2) for output, pool in zip(outputs, poolings)] # Applying max-pooling filters\n",
    "        output = torch.cat(outputs,1)\n",
    "        return output\n",
    "        \n",
    "#         outputs = []\n",
    "#         for h, f in zip([1,2,3], [300,300,300]):\n",
    "#             conv_h = nn.Conv2d(in_channels=1, out_channels=f, kernel_size=(h,10), stride=1, padding=0)\n",
    "#             output_h = conv_h(x).squeeze(3)\n",
    "            \n",
    "#             pool_h = nn.MaxPool1d(output_h.size(2))\n",
    "            \n",
    "#             output_h = self.tan(output_h)\n",
    "            \n",
    "#             output_h = pool_h(output_h).squeeze(2)\n",
    "            \n",
    "#             outputs.append(output_h)\n",
    "#         output = torch.cat(outputs,1)\n",
    "#         return output\n",
    "        \n",
    "    # Overwriting the base forward function in nn.Module \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Retrieve the embedding of the words\n",
    "        output = self.embedding(x).unsqueeze(1)\n",
    "#         display('Output shape after embedding : ', output.shape) # batch_size * 1 * max_seq_len * embed_dim\n",
    "\n",
    "#         # Convolutional phase\n",
    "#         output = self.conv(output).squeeze(3)\n",
    "#         self.pool = nn.MaxPool1d(output.size(2))\n",
    "#         display('Output shape after convolution : ', output.shape) # batch_size * num_filter * length\n",
    "        \n",
    "#         # Tanh phase\n",
    "#         output = self.tan(output)\n",
    "#         display('Output shape after tanh : ', output.shape) # batch_size * num_filter * length\n",
    "        \n",
    "#         # Pooling phase\n",
    "#         output = self.pool(output).squeeze(2)\n",
    "#         display('Output shape after pooling : ', output.shape) # batch_size * num_filter\n",
    "        \n",
    "        # Whole convolutional layer with several filters\n",
    "        output = self.perform_convolution(output)\n",
    "#         display('Output shape after whole convolutional layers:', output.shape) # batch_size * num_filter\n",
    "\n",
    "        # Return the final output\n",
    "        output = self.classifier(output)\n",
    "#         display('Output shape after classifier:', output.shape) # batch_size * num_classes\n",
    "        return output\n",
    "    \n",
    "    # Initiate the parameters to a normal distribution with a mean of 0 and a standard deviation of 1\n",
    "#     def init_params(self):\n",
    "#         for param in self.parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 torch.nn.init.normal_(param, mean=0, std=1)\n",
    "                \n",
    "discriminator = CNNDiscriminator()\n",
    "\n",
    "# ngpu = 0 # Number of GPUs available. Use 0 for CPU mode.\n",
    "# device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\") # Decide which device we want to run on\n",
    "# Enables GPU computing to speed up network training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print(discriminator)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, values, labels):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.values = values\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.values[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[46, 20, 12,  1, 16],\n",
       "        [44, 17,  5, 29,  6],\n",
       "        [13,  8, 40, 43,  4],\n",
       "        [27, 40, 41, 21,  9],\n",
       "        [20,  0, 11, 35, 22],\n",
       "        [ 2,  6, 29, 37, 45],\n",
       "        [22, 15, 15, 40, 11],\n",
       "        [14, 11, 24, 10, 17]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5530, 0.4470],\n",
       "        [0.5768, 0.4232],\n",
       "        [0.5487, 0.4513],\n",
       "        [0.5689, 0.4311],\n",
       "        [0.5636, 0.4364],\n",
       "        [0.5686, 0.4314],\n",
       "        [0.5575, 0.4425],\n",
       "        [0.5595, 0.4405]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = torch.randint(low=0,high=50,size=(8,5)) # 8 sentences of 5 words\n",
    "display(test)\n",
    "a = discriminator(test)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training part : features needed\n",
    "\n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCELoss() # nn.BCEWithLogitsLoss stabler ? \n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "# beta1 = 0.5\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create a batch of data\n",
    "samples = torch.randint(low=0,high=50,size=(400,5))\n",
    "labels = torch.randint(low=0,high=2,size=(samples.size(0),1)).float() \n",
    "train_dataset = MyDataset(samples, labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/50], Loss: 0.6643, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [2/50], Loss: 0.6608, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [3/50], Loss: 0.5828, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [4/50], Loss: 0.7352, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [5/50], Loss: 0.9316, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [6/50], Loss: 0.8088, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [7/50], Loss: 0.8178, Accuracy: 12.50%\n",
      "Epoch [1/1], Step [8/50], Loss: 0.7057, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [9/50], Loss: 0.9488, Accuracy: 12.50%\n",
      "Epoch [1/1], Step [10/50], Loss: 0.6472, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [11/50], Loss: 0.6805, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [12/50], Loss: 0.7056, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [13/50], Loss: 0.7944, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [14/50], Loss: 0.7195, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [15/50], Loss: 0.6753, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [16/50], Loss: 0.6495, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [17/50], Loss: 0.6612, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [18/50], Loss: 0.3944, Accuracy: 100.00%\n",
      "Epoch [1/1], Step [19/50], Loss: 0.5360, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [20/50], Loss: 0.9057, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [21/50], Loss: 0.7424, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [22/50], Loss: 0.8203, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [23/50], Loss: 0.5872, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [24/50], Loss: 0.8015, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [25/50], Loss: 0.6271, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [26/50], Loss: 0.7013, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [27/50], Loss: 0.5857, Accuracy: 87.50%\n",
      "Epoch [1/1], Step [28/50], Loss: 0.8213, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [29/50], Loss: 0.5153, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [30/50], Loss: 0.7955, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [31/50], Loss: 0.8910, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [32/50], Loss: 0.7319, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [33/50], Loss: 0.6830, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [34/50], Loss: 0.6954, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [35/50], Loss: 0.6530, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [36/50], Loss: 0.7096, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [37/50], Loss: 0.7052, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [38/50], Loss: 0.6151, Accuracy: 87.50%\n",
      "Epoch [1/1], Step [39/50], Loss: 0.7939, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [40/50], Loss: 0.8768, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [41/50], Loss: 0.8180, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [42/50], Loss: 0.7823, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [43/50], Loss: 1.0338, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [44/50], Loss: 0.6915, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [45/50], Loss: 0.6882, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [46/50], Loss: 0.6945, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [47/50], Loss: 0.7216, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [48/50], Loss: 0.7688, Accuracy: 12.50%\n",
      "Epoch [1/1], Step [49/50], Loss: 0.6715, Accuracy: 75.00%\n",
      "Epoch [1/1], Step [50/50], Loss: 0.7632, Accuracy: 25.00%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (sentences, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Run the forward pass\n",
    "        outputs = discriminator(sentences)\n",
    "        true_probability = outputs[:,1].unsqueeze(1)\n",
    "        loss = criterion(true_probability, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        predicted = predicted.unsqueeze(1)\n",
    "        correct = (predicted == labels).sum().item() \n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        # Print the results \n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        self.dataset = None # panda dataframe : TODO : faire que ce soit le constructeur qui load le dataset (paramètre)\n",
    "        self.vocabulary = None # dictionnary of strings with integer indexes\n",
    "        \n",
    "        self.sentences_original = None  # list of strings\n",
    "        self.sentences_tokened = None # list of (list of strings)\n",
    "        self.sentences_indexed = None # list of (list of integers)\n",
    "        \n",
    "        self.descriptions_original = None # list of strings NOT USED FOR NOW \n",
    "        self.descriptions_tokened = None # list of (list of strings)\n",
    "        self.descriptions_indexed = None # list of (list of integers)\n",
    "        \n",
    "        # Delelte tous les trucs intermédiaires inutiles et tout simplement les mettre en output des fcts intermédiaires ? \n",
    "    \n",
    "    # Function loading the dataset \n",
    "    def load_dataset(self, name):\n",
    "        dataset = pd.read_excel(name, encoding='latin1')\n",
    "        dataset.columns = ['Time', 'Name', 'Race', 'Class', 'Backstory']\n",
    "        dataset = dataset[['Name', 'Backstory']]\n",
    "        dataset = dataset.dropna()\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        self.dataset = dataset\n",
    "        self.descriptions_original = self.dataset[['Backstory']].values.tolist()\n",
    "        self.names = self.dataset[['Name']].values.tolist()\n",
    "    \n",
    "    # WIP\n",
    "    def preprocess(self, min_sentences=4, max_sentences=40, min_descriptions=20, max_descriptions=1000):\n",
    "        self.tokenize_dataset()\n",
    "        \n",
    "        self.create_vocabulary()\n",
    "        self.vocabulary_mapping()\n",
    "        \n",
    "        self.sentences_indexed = self.size_filtering(self.sentences_indexed, min_sentences, max_sentences)\n",
    "        self.descriptions_indexed = self.size_filtering(self.descriptions_indexed, min_descriptions, max_descriptions)\n",
    "        \n",
    "        output_sentences = self.tensors_conversion(self.sentences_indexed)\n",
    "        output_descriptions = self.tensors_conversion(self.descriptions_indexed)\n",
    "        \n",
    "        return output_sentences, output_descriptions\n",
    "    \n",
    "    # Function tokenizing the dataset into backstory and sentences \n",
    "    def tokenize_dataset(self):\n",
    "        descriptions_output = []\n",
    "        sentences_output = []\n",
    "        for i in range(0, len(self.dataset)):\n",
    "            descriptions_output.append(self.tokenization_backstory(self.dataset['Backstory'][i], self.dataset['Name'][i]))\n",
    "            sentence_temp = self.tokenization_sentences(self.dataset['Backstory'][i], self.dataset['Name'][i])\n",
    "            sentence_temp = [l.split() for l in sentence_temp] # Si on veut sentences original c'est ici\n",
    "            sentences_output.append(sentence_temp)\n",
    "            \n",
    "        self.descriptions_tokened = descriptions_output\n",
    "        self.sentences_tokened = [item for elem in sentences_output for item in elem]\n",
    "    \n",
    "    # Function creating the vocabulary with every unique word being given a unique index\n",
    "    def create_vocabulary(self, backstory = True):\n",
    "        list_of_words1 = [item for elem in self.descriptions_tokened for item in elem]\n",
    "        list_of_words2 = [item for elem in self.sentences_tokened for item in elem]\n",
    "        list_of_words = [y for x in [list_of_words1, list_of_words2] for y in x] # NOT OPTIMAL BUT FOR NOW\n",
    "        list_of_unique_words = list(set(list_of_words))\n",
    "        vocabulary = {word:list_of_unique_words.index(word) for word in list_of_unique_words}\n",
    "        self.vocabulary = vocabulary\n",
    "    \n",
    "    # Mapping every word of every description/sentence to it unique index\n",
    "    def vocabulary_mapping(self):\n",
    "        outputs = []\n",
    "        for d in self.descriptions_tokened:\n",
    "            outputs.append([self.vocabulary[word] for word in d])\n",
    "        self.descriptions_indexed = outputs\n",
    "        \n",
    "        outputs = []\n",
    "        for s in self.sentences_tokened:\n",
    "            outputs.append([self.vocabulary[word] for word in s])\n",
    "        self.sentences_indexed = outputs\n",
    "        \n",
    "    # Keep only sentences/descriptions of a given length to optimize training\n",
    "    def size_filtering(self, list_of_list, size_min, size_max):\n",
    "        list_of_list = [l for l in list_of_list if size_min <= len(l) <= size_max]\n",
    "        return list_of_list\n",
    "    \n",
    "    # Return a tensor with all the descriptions/sentences padded so that it has the same length\n",
    "    # TODO : return a dataset object instead of a tensor \n",
    "    def tensors_conversion(self,x):\n",
    "        output = list(map(torch.LongTensor, x))\n",
    "        output = nn.utils.rnn.pad_sequence(output, padding_value=len(self.vocabulary))\n",
    "        output = torch.transpose(output,0,1)\n",
    "        return output\n",
    "        \n",
    "    ###################### ELODIE'S FUNCTIONS (tu peux rajouter tes commentaires stp) #####################################    \n",
    "    \n",
    "    def tokenization_backstory(self, text, name):\n",
    "        text = self.pre_tokenization(text, name, 1)\n",
    "        words = text.split()\n",
    "        return [word.lower() for word in words]\n",
    "    \n",
    "    def tokenization_sentences(self, text, name):\n",
    "        text = self.pre_tokenization(text, name, 0)\n",
    "        words = text.split('.')\n",
    "        return [word.lower() for word in words]\n",
    "\n",
    "    def pre_tokenization(self, text, name, end):\n",
    "        text = text.replace(\"?\", \".\")\n",
    "        text = text.replace(\"!\", \".\")\n",
    "        text = text.replace(\".\", \" .\")\n",
    "        text = text.replace(\"“\", \"\")\n",
    "        text = text.replace(\"”\", \"\")\n",
    "        text = re.sub(\"\\d+\", \"_Number_\", text)\n",
    "        if name in text: \n",
    "            text = re.sub(name, \"_Name_\", text)\n",
    "        else: \n",
    "            name = self.remove_punctuation(name)\n",
    "            for i in range(0, len(name)):\n",
    "                text = re.sub(name[i], \"_Name_\", text)\n",
    "        if end == 1:\n",
    "            text = text + \" _end_\"\n",
    "        return text\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        text = text.replace(\"“\", \"\")\n",
    "        text = text.replace(\"”\", \"\")\n",
    "        words = text.split()\n",
    "        remove = string.punctuation\n",
    "        remove = remove.replace(\"-\", \"\")\n",
    "        table = str.maketrans('', '', remove)\n",
    "        stripped = [w.translate(table) for w in words]\n",
    "        return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "preprocessor.load_dataset('data.xls') # Load the dataset\n",
    "output_sentences, output_descriptions = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1931, 996])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([26645, 40])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "37549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output_descriptions.shape, output_sentences.shape)\n",
    "# display(d[0], s[0])\n",
    "\n",
    "vocabulary = preprocessor.vocabulary\n",
    "display(len(vocabulary))\n",
    "\n",
    "desc_original = preprocessor.descriptions_original\n",
    "# display(desc_original[9])\n",
    "\n",
    "desc_tokened = preprocessor.descriptions_tokened\n",
    "sent_tokened = preprocessor.sentences_tokened\n",
    "# display(desc_tokened[9])\n",
    "\n",
    "desc_numeric = preprocessor.descriptions_indexed\n",
    "sent_numeric = preprocessor.sentences_indexed\n",
    "# display(desc_numeric[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test divers size distribution avec desc_numeric or sent_numeric\n",
    "display(len(desc_numeric))\n",
    "\n",
    "lens = [len(d) for d in desc_numeric]\n",
    "plt.hist(lens, bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "# u,c = np.unique(lens, return_counts=True)\n",
    "# display(u,c)\n",
    "\n",
    "lens_filtered = [l for l in lens if 15 <= l <= 900]\n",
    "display(len(lens_filtered))\n",
    "plt.hist(lens_filtered, bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/291], Loss: 0.6951, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [2/291], Loss: 0.6996, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [3/291], Loss: 0.6977, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [4/291], Loss: 0.7069, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [5/291], Loss: 0.6956, Accuracy: 25.00%\n",
      "Epoch [1/1], Step [6/291], Loss: 0.6986, Accuracy: 37.50%\n",
      "Epoch [1/1], Step [7/291], Loss: 0.6891, Accuracy: 50.00%\n",
      "Epoch [1/1], Step [8/291], Loss: 0.6893, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [9/291], Loss: 0.6893, Accuracy: 62.50%\n",
      "Epoch [1/1], Step [10/291], Loss: 0.6887, Accuracy: 75.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-f70d67331802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Run the forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscri_test2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mtrue_probability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-69ff43ddb84f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# Whole convolutional layer with several filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;31m#         display('Output shape after whole convolutional layers:', output.shape) # batch_size * num_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-69ff43ddb84f>\u001b[0m in \u001b[0;36mperform_convolution\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperform_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Apply convolutional with filters size and number of filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtan_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Apply tanh function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mpoolings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Prepare the max-pooling filters over time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-69ff43ddb84f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperform_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Apply convolutional with filters size and number of filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtan_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Apply tanh function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mpoolings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Prepare the max-pooling filters over time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Quick training test for the text\n",
    "samples = output_preprocessor\n",
    "labels = torch.randint(low=0,high=2,size=(samples.size(0),1)).float() \n",
    "train_dataset = MyDataset(samples, labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "discri_test2 = CNNDiscriminator(voc_size=len(vocabulary)+1)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (sentences, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Run the forward pass\n",
    "        outputs = discri_test2(sentences)\n",
    "        true_probability = outputs[:,1].unsqueeze(1)\n",
    "        loss = criterion(true_probability, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        predicted = predicted.unsqueeze(1)\n",
    "        correct = (predicted == labels).sum().item() \n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        # Print the results \n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
